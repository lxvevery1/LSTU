Тюрин Алексей Сергеевич

Данные становятся большими как только не помещаются на одном ПК
а также неструктурированные
Часть данных из логов мобильного приложения, веб сервера, фронт-енд десткоп ПО

Объем информации ТБ, ПБ - большие данные

Когда строим большие системы столкнемся с проблемой больших данных
фронт+бек+бд
1 млн пользователей вызывают большое кол-во событий, на каждого нужны логи
нужны балансировщики, горизонт. масштабирование (экземпляр по поднимается несколько раз)
куча приложений, куча пользователей -> Big Data
Если система очень обширная, тоже Big Data

один датчик в секунду может 100 сигналов * 100 датчиков -> 10 000 сообщений в сек.

Big Data тяжело обрабатывать данные и не все инстурменты способны на это

Чтобы собирать и хранить джанные придумали:
для хранения:
HDFS, колоночные БД, документоориентированные БД,

Одномерные таблицы (с одним столбцом).
Обрабатывать будем распределенно Spark, Flink, Kafka

Жизненный цикл данных
Собираем, храним, готовим к обработке, визуализируем

Воркер - узел выполнения
Можно задавать задачу (функция Python), распределим её по воркерам: выполните и верните.
Мастер нода бывает одна.
Воркеров много.
Для средних задач 10 воркеров
Воркеры могут добавляться и удалться автоматически
Мастер нода автоматически раздает полученный от клиента код воркерам.

Hadoop - распределенная файловая система
данные хранятся паркетами (файлы, в которых зашиты наборы данных)
DataFrame может представлять паркет
Паркет может разделяться на части. Spark должен сконфигурироваться с хадопом чтобы каждый нод распределился с сервером
каждый воркер должен из отдельной ноды читать кусок данныъ и агрегированные данные отправлять


Для задач данные могут быть выбраны рандомно, а вот тема должна быть единой для всех лаб.
