# HDSF & HADOOP

HDFS - часть HADOOP

Можно устанавливать весь HADOOP FRAMEWORK, так и по отдельности

В прошлый раз был Spark, теперь HDFS.

Утилиты - HDFS - Hadoop Distributed File System

Спроектироована для хранения больших файлов.

Большие файлы - говорят Hadoop хранилище для гб+ файлов. 10-100 гб легко можно хранить,

HDFS состоит из мастер и рабочей ноды - Name Node и Data Node

Name Node - сервер для управления данными - структура папок, информация о кусочках данных разбитая на блоки

Name Node не хранит данные сама по себе. Координирует клиентов на чтение-запись. Их может быть 1 и более.
При отказе всех падает вся система.

Data Node - хранят сами данные в блоках. Дробим файлы на блоки - единица хранения блок
Реплицируюи между собой блоки файлов - для отказоустойчивости.
Пробовали подключать один из воркеров на лету, при этом задача будет продолжать выполнение.

Вычисления можно повторить, но придется снова ждать
С данными иначе: если нода выходит из строя, то данные могут быть потеряны (диски, сервер)

Дата может быть одной, но в случае сбоя данные будут утеряны.

Как минимум, 3 ноды по-хорошему.
Обеспечивает скорость и надежность.

Дата ноды посылают сигнал Name Node и проверяет жизнь дата ноды

Разбиваем на блоки фикс. размера.
Размер либо 128, либо 256. Блоки распределяются между дата нодами
Name Node знает где какой блок хранится. Части файла может быть записаны на разных дата нодах.

Вроде заняли 3ТБ места, но раз файлфы разбиты на блоки, то ускоряемся за счет параллельного доступа к каждой ноде.

Все это хорошо стакается со Spark. Каждая нода может читать Data Node, увеличивая и чтение данных

Map Reduce - модель программрования, располагаем ресурс-менеджером (мастер-нода) и воркерами.
Map - отображение
Reduce - сведение

Сначала выполняем Map, выполняем партицирование (partition) - принимает на вход ключ и значение и генерирует набор данных.
Map может выполняться параллельно на множестве узлов

Reduce сортируется и группируется по ключу, для каждой Unique Pair запускается Reduce и применяет итератор всех значений для данного ключа (параллельно)

Например, подсчёт слов по большому массиву текста.
Сколько раз всетрчается слово Азбука.
Делаем функцию Map для каждого слова в документе создаем пары ключ-значение
Выполняем сортировку и группируем. Сколько раз встретится Азбука, объединяем по ключу и получаем
массив из чисел (ключей).
При этом Reduce не обязательно должен суммировать — это лишь частный случай.
Reduce может делать что угодно: искать максимум/минимум, собирать список, усреднять, фильтровать и т.д.
Reduce - суммирование всех значений - ключ и общая сумма для подсчёта повторений слов.

Kubernetes поверх него делают OKD, OpenShift -
Apache Achebase работает поверх HDFS и нужна дял хранения временных рядов (датчик температуры, например) (с временной меткой)

Apache Flink - потоковая обработка данных. Связано с брокерами сообщений - канал с непрерывно падающими сообщениями, чтобы их отправить куда-то в другой канал.

Airflow & APache Tes - Раз в час выполнить запрос в БД

HADOOP - найфай - флинк или тест, но более старый подход. Основной недостаток - хочется все исходники хранить в гит репо, а он не позволяет это делать.

Используй HADOOP когда данные большие - логи, нармиер.
Не стоит использовать в небольших задачах.

Система состоит из Бэк+фронт+ПСГС - не надо юзать Hadoop

Когда нужна постребность в построении Extract Transform Load (ETL) процессов

Данные достать, преобразовать, представить результат

Если хочется сделать так, чтобы было не через код, тогда можно посмотреть на Hadoop.

...

<b>Шардирование</b> - разбиение на мелкие куски. Горизонтальное масштабирование - есть сервер с кусочками данных (шард)
Каждый шард связывается с остальными шардами в БД,

У каждой шарды должен быть ключ - поле по которому распределяется

Сингл-нод база данных - железку на 1ПТ - очень дорого, а вот 1000 серверов по 10ТБ можно
Отказоустойчивость и доступность. Географически распределенные данные хорошо ложатся на шарды

Минусы - сложность реализации, накладные расходы (много серверов), проблемы с JOIN разных таблиц

Шардирвоание - когда поделили данные по какому-то признаку, без смешивания кусков между собой.

Шардирование - нативная функция ПСГС.

Шардирование можно имитировать на уровне кода. Подключение к БД и поставьте условие - если запрашиваем данные по студентам с буквы А,
то выполяем запросы по одной БД, для других букв использовать другие БД.

<b>Реплицирование</b> - копирование данных.
Появляется избыточность (2 копии), но кучаа плючов

Если есть 2 реплики - одна и вторая копия.

Аналитики будут читать из реплики, а само приложение будет на ориге.


Мастер-нода + нода хранящая реплику.
Реплицирование не такой простой механизм. А если данные будет менятсья во время копирования,
кусочек удалился повредилась система. ПСГС умеет все это под капотом.

Как избежать изменения данных при копировании
Включить блокировку - на пару секунд копирования.

Реплицирование - копия. Если что-то нехорошее произойдет с серверами, делаем резервное копирование.
Постоянно гоняем данные с одной ноды на другую, сложнее чем шардирование, конфликты данных.

Реплицирование бывает побайтное - физическая репликация. Rade-конетроллер.
Компьютер думает тчо пишет на один диск, а рейд ведет чтение сразу на несколько

Баз-данное копирвоание - логическое - через публицации (триггеры) при чтении из указанных таблиц.
На репликах создаем подписку.

# Вопрос: надо ли разобрать настройку репликации

В primary выполняем скрипт (start.sh)
скопировать новый файл, рестартануть конфигурацию

В спомогательной ноде скрипт зашит в старт, определяем ENV, и записываем в конфиг адрес primary Node
