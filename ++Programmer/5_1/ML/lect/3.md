# Методы классификации данных
2.1 Постановка задачи классификацтт
2.2 Точность классификации
2.3 Наивный баиесовский метод

На входе множество определенных значений. Элемент множества состоит из признаков (feature).
Множество признаков, которое берется - из пр-ра Rn

Представляет какое-то числовое значение, в любом случае надо преобразовать в числовой вид (label, binary, one hot)

Множество классов (меток) - если кол-во классов сравномо с кол-вом объектов, то применяются методы по увеличению
объема данных (метод аугментации). Задача распозванавания образов - частный случай классификации.

В качестве класса может быть человек. Кто из людей прошел через ... Кол-во данных, чтобы обучить и настроить систему
большое. Технология распознавания лиц - пример.

В кластеризации классы не заданы.

Для каждого объекта фиксируем класс (известные объекты).
Множество объектов, множество классов - сопоставить каждому объекту его класс - задача классификации.

# Постановка задачи классификации II

Классификация похожа на задачу регрессии. Дано множество точек. На выход
Отличие - если в задаче регрессиии отклик - вещественная величина (непрерывно-значная)
В классификации множество выходных значений - дискретное.
Если выходное множество - множество классов бинарное,
Если строим зависимость, если есть непрерывное значение и отыскивать пороговое значение. > ? класс_1 : класс_другой.

Вход - множество данных. Определить такого отображения, которое ставит в соответствие каждому вектору элемент из
множества C. Можно классифицировать как обучение с учителем.

Альтернатива - можно ставить соответствия не на прямую, а на определение поверхностей, разделюяющиз пространство на
несколько областей. Если есть объекты, описываемые двумя признаками, то ищем кривые.

Простейший случай - задача бинарной классификации. Множество классов из которых выбираем принадлежность, Мощность = 2 (Класс_0, Класс_1).
(позитивный, негативный) (1, 0).

Вектор в скаляр.

ВФВА - на входе вектор, на выходе тоже вектор - в качестве выходного веектора выступает множество векторов - vec(0,1). Относится ли
вектор к какому-нибудь классу.

Когда векторная функция - на выходе тоже вектор. На выходе получается вектор из (1, 1), либо наоборот (0, 0) - не принадлежит никакому классу.

ВФВА - элемент вектора может принимать значение от 0 до 1 (вероятность, степень уверенности).

Важным свойством классификации явлвяется <b>линейная разделимость</b>.

Задача линейно-разделимая, если существует линейная функция, которая (2D - прямая, 3D - плоскость. Объекты относятся к одному классу, а те к дркгому)

Решать задачу можно разными способами. Каждому вектору поставить в соответствие какой-то класс. Связь задач с регрессией (функционал качества, целевая функция,
которую минимизируем). Задача сказать насколько хорошо или плохо модель описывает данные. Уметь оценивать насколько хорошо или плохо задача рещается

В начале решается промежуточная задача, строится матрица ошибок (confusion matrix), столбцы - классы которые дает наша модель
на пересечениях ставим 1. Если взяли первую строку данных, объект относится C2, а модель выдала C21,
Сумма элементов матрицы даст кол-во строк (объем) множества данных на которые строим оценку.
T (True), E (Error). Если элемент попадает на главную диагональ - ответ правильный (k штук)
Все остальное - неправильный ответ.

Множество вещественных чисел линейно упорядоченно (всегда  можно сравнить). Нелинейные не сравнимы. В матрицах еще хуже.
Поэтому чтобы оценить качество модели преобразуем матрицу к модели. В качестве меры для оценки качества модели используется точность -
суммируем элементы на главной диагонали, делим на m (сумма всех элементов матрицы). Минимальное значение (0), максимальное значение (1).
1 - модель идеально правильно решила систему. 0 - не решила.

<!-- Когда 2 множества совпадают - отношение -->
<!-- Когда 2 множества не совпадают - соответствие -->

<b>Accuracy</b> часто показывает хорошо или плохо модель классифицируется.
Величина описывающая
Acc = summ(f) / m - f по главной диагонали.
Error = summ(r) / m - r - элемент не по главной диагонали

Уровень ошибки измеряется от нуля до одного
<b>Precision</b> - модель отнесла объекты к какому-то классу и сколько из классифицируемых классифицированы верно.
Есть класс людей, доступ которым надо ограничить - отдельно считаем долю из тех людей, которые отнесены к нежелательному классу.
Сколько мы не пропустим хороших людей. Precision - доля нежелательных людей - их не пропускаем.

<b>Чувствительность</b> (recoll, sensivity) - почти то же самое - кол-во правильно определнных объектов делим на сумму элементов строки
Элементы строки - объекты какого-то класса. А сколько наша модель классифицировала элементов строки (Чем больше sensivity, тем меньше плохих людей
пропустим).

<b>Специфичность</b> - мера того что тот объект относящийся к классу G не явлвяется его объектом. Вычеркиваем j строку, j столбец.
Можно узнать насколько нежелательный или насколько желательный.


# Бинарная классификация

Есть 2 класса - C1, C2.
C1 - Positive
C2 - Negative

Кол-во строк с Positive - P
Кол-во строк с Negative - N

Есть 2 класса: матрица потерь будет 4 [2x2]
Обнозначения TP FP
             TN FN

TP - True Positive - верное отнесли к положительному классу
TN - True Negative - верное отнесли к отрицательному классу
FP - False Positive - ложно отнесли к положительному классу
FN - False Negative - ложно отнесли к отрицательному классу

Соотношения:
P = TP + FN
N = TN + FP

<b>F-мера</b> - баланс (гармоническое среднее) между метриками точности (P) и полноты (R).

F = (2PR) / (F + R)

<b>ROC-кривая</b> - строится Ox: FPR, Oy: TPR.
Значение по диагонали - неразличимость. ROC-кривая будет лучше себя вести (чем больше выражен угол, тем лучше)

AUC - Area Under the Curve

<B>ROC-AUC</B> - кривая + площадь под этой кривой

PR-AUC - кривая 0 для несбалансированных классов.
