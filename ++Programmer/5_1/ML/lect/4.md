Точность классификации IV

Что лучше - <u>прочитать неинтересное</u> или пропустить важное? А если важное
сообщение будет уходить в спам - это ошибка. Если учитывать вес, то значимость
ошибок будет другая, модель классификации построим другим образом.

Система анализа дефекта продукции. Хорошую продукцию отнести к браку или плохую
в товары. Обе ошибки, но одна из них хуже.

Если используем ту же модель, что и для классификации. Адекватность - мера того,
насколько модель адекватна и соответствует процессу. Натурное испытание -
модель + испытания - получили полосу и оценили её.

Вместо этого используются другие оценки о множестве данных.
Оценка классификации на тестовом множестве.

Оценка адекватности. Какое тестовое множество выделять ? 20, 30, 15% - все зависит от данных
если данных очень много, то можно и 20%, если данных очень мало, то 20 уже жалко выделять.

Допустим, 20%. С первого ? Нет, они могут быть уже упорядочены,
рандомно? Они могут быть разбиты на страты - жители разных городов.
Разделить на эти части и выделить пропорционально кол-во объектов из этих данных.

Со всех страт по определенной доле - лучший.

Случайный выбор тоже неплох, хотя и зависим от случая итоговой выборки.

Результаты, которые решают, приходят к разным выводам.
Для того чтобы сравнить разные результаты моделей, используется начальное
значение датчика псевдо-случайной выборки.

Кроме понятия обучающего и тестового, есть <u>валидационное множество</u>.
Его разбирать не будем.

Оценка адекватности.
На тестовом множестве можем сравнивать разные ошибки. Чем меньше её значение - тем лучше

Оценка ошибки на обучающем и на тестовом множествах.
Считается, что ошибки интуитивно понятны. Если ошибка на тестовом колосально отличается
от обучающего, значит модель не настроилась. Это какой-то индикатор конкретно занятой модели.

Приближенно равны - условное значение.

Еще одна мера для оценки адекватности - крос-проверка (крос-валидация).
Крос-валидация используется, когда исходное мн-во данных небольших размеров.
Какие-то случаейные добавления, с точки зрения статистики могут прийти к понижению смещенности
модели. Есть множество данных, выбираем часть данных, на оставшейся части строим модель и считаем
ошибку. Затем выбираем спрятанное и забираем другую выборку в карман.
С одной стороны, используем всю выборку целиком и оцениваем данные, которые не учитывали.

Есть разные подходы - по 20%, случайно по одному примеру убираем множество данных.
Техника типа Джек-knife.

Жалко в тестовой что-то выкидывать. С другой стороны, на каждой подвыборке очень много строится (100/20 = 5),
а с тестовым один раз. Сравниваем не точность построения модели, а их адекватность - насколько хорошо описывает модель.

Классов может быть много, бинарная классификация. F-мер, R-кривых - для бинарных, но есть и обобщения на многомерный случай.
Многие задачи классификации, в которых есть несколько классов могут быть сведены к задаче с двумя классами.

Если всего 10 классов, берем объекты первого класса, а все остальное считаем вторым классом.
Потом строим вторую модель [2-10] 2 - 0, [3-10] - 1.
Получается что вместо одной модели многоклассовой классификации решаем 9 задач - зато сводится к бинарной классификации.

Рассмотрим 3 способа:
Naive Bayes Classifier (NBC) - бенчмарк с основой, если какой-то метод хуже него, то его не стоит применять к реальной задаче.
Родился из формулы Байеса. Задача - определить вероятность отнесения объекта x к классу Cj, при условии что известен вектор
описания объекта x. Есть описание вектора - множество точек, нужно определить к какому классу он относится.

Апостериорная вероятность - (post - после чего-то) - уже считаем что объект x известен. После того как взяли объект x,
посчитали вероятности (k), в качестве решения задачи выбираем класс G, который соответствует большей вероятности.
Если несколько вероятностей одинаковые, то они неразличимы. Это принцип <u>максимума апостериорной вероятности</u>.

Метод опорных векторов - что такое опорные вектора.
Линейные опорные плоскости.

При решении задачи бинарной классификации - 2 класса - 2 вероятности. Как принцип максимума будет выглядеть?
if > then 0 else 1.
Формула байеса - в знаменателе вычислем априорную вероятность на основе информации, которая была до этого.
Эта вероятность умножается на условную вероятность того, что объект описывается x тем что известно что
реализовался класс Cj.
Считаем строки m - кол-во шаров (m = 3 красных, m = 7 синих).

X - вектор, который состоит из n - признаков значений.
Векроятность того что реализовался класс Cj, и признаки приняли x1, x2, x3, ... , xn
Используя формулу условной вероятноти, разбиваем на произведение условной вероятности.
Сформировался класс Cj и первый признак стал x1.

Оцениваем вероятность мужчины: который высокий, кареглазый и 1.85 рост. Мы знаем, что зашел мужчина.
Кареглазый коротковолоый мужчина 1.85 - произвдеение волосы коротки (сколько среди мужчин короткие волосы)
* вероятность карих глаз и роста 1.85. Думаем что это мужчина. Находим в группе мужчин с короткими волосами и
сколько из них имеют карие глаза (отсеялись м с длинными волосами). М с короткими волосами и с кариеми глазами
и сколько из них имеют рост >=185, перемножаем эти вероятности и получаем вероятность отнесения объекта к классу.

...

Ключевой момент - та модель что в классификации - наивная - наивно предполагаем что все признаки независимы.
x3 зависит только от класса Cj, без зависимости между x-ов.

То есть цвет глаз, рост и длина волос не зависмы друг от друга в NBC.
В этом случае всё очень просто: отдельно считаем вероятность появление признака не зависимо от классов.

Есть множетсво значений, оставляем те строчки, что принадлежат к классу Cj. Дискретная шкала (цвета)
оцениваем сколько раз встретился цвет для класса. В результате получаем кол-во соотв. значений.

Если переменная является не номинальной, а является непрерывной (уровень заплат).
В этом случае разбивается мн-во значений на интервалы изменения переменных (до 100; от 100 до 200; 300+)
Можем оценивать появление признака, ценой потери непрерывности. Знаменатель для всех классов один и тот же,
поэтому его можно не вычислять. Считаем для каждого класса только числитель.

Нужно понимать параметры функции пакета ( NBC в частности ).

Лучший способ узнать добротность результата - сравнение с результатом другой моделью.
