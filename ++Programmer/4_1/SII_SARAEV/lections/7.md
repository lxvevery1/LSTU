# Нейронные сети

Когда говорят ИИ - подразумевают что используется нейронные сети, в этом курсе
нейронные сети будут изучены в малом объеме, main курс в магистратуре

Про-экспертные системы, про-нечеткие врядли уже где-то будут изучаться


## Основы теории нейровнных сетей

Поговорим о теории, истории, основные структурные элементы.
Наиболее популярные классы - нейросети прямого распространения

Поговорим про сети с обратными связями и о глубоких нейросетях
В заключении соединим нечеткие системы и лингвистического языка.

Системы на нечеткой логике тяжело обучаемы.

Нейросети именно что обучаются. Но у нейросетей непонятно как она получила
выход. Как можно скомбинировать нейросети и нечеткие системы? Достоинства одной
и другой - получится нейронечеткая система.

## История развития нейронных сетей

В США была сделана научная работа.
ПРи построении нейросетей есть 2 подхода - информационный и нейробионический
Как реально работают системы и построить на их

В 1949г Хеббом были предложени подходы к построению некоторых нейроподобных структур
1957г - нейросеть - перцептрон розеблатта позволял решать логические задачи -
линейной классификации
1969г - Минкий и Пейперт - в этой работе минский показывает что эти нейросети имеют
очень ограниченную возможность применения - XOR не может быть решена с использованием
перцептрона на тот момент.
Основываясь на данной работе люди, отвечающие за финансовые средства науки стали
выделять средства
1982г - новый тип нейросетей (с обратными связями) -  одной стороны это более сложно,
но выбирая определенным образом веса, формализуя задачу...
1984г - самоорганизующаяся карта Кохонена. Решает задачу кластеризацию данных.
.
Многослойные перцептроны могут быть обучены - там нет ничего сложного - лишь мат.
анализ, который был предложен в 19 веке. Нет никаких принципиально новых идей

Процедура обратного распространения ошибки - вычисление градиента весов. Методы теории
оптимизации.
Метод оптимизации гладкой функции
Как вычислить функции x^2.
Градиентный метод - градиент показывает направление возрастания, анти - убывания
Способ распространения ошибки основан на граденте

1989г - появляется Ян ЛеКун - родил понятие сверточных нейронных сетей. Могут
распознавать почтовые индексы

1998г - Ян ЛекКун доработал сверточные нейросети для распознавания банковских чеков.
Для обучения тех структур в которых много слоев могут применяться умные способы
выбора весовых коэффициентов

2010г - когда используются многослойные конструкции градиент утихает.
2012г - сверточные нейросети, использующие образы ImageNet - позволили улучшить
показатели наилучшей модели, а применение глубоких сетей позволили исправить


## Что такое нейросети издалека?

Нейросети - формальные представления органических сетей.

Искусственный нейрон.
Инфомрация поступает в тело клетки из дендрита
Посредством связи аксона из одной клетки к дендритам другой клетки
-> синапс (синапсическая щель - вещество обладающее электрическим зарядам)

Пусть нейрон будет искусственный - сома, дендриты (провода), аксон (инфа идет дальше)

Модель, представленая слева - модель Сомы - преобразует i в o.
Нейрон каким-то образом обрабатывает инфу и передает инфу (аксон)
Есть входные сигнали и соответствие некоторых параметров - весы нейрона.
Каждому входному сигналу соотвествует вес - усиливает или ослабляет сигнал.
Искусственный сигнал преобразует векторную функцию в скаляр.
На первом этапе вычислется xn на wn
Уровень активности нейрона. Функция активации как правило является нелинейной
Функция активации - скалярная функция скалярного аргумента
Один нейрон выполняет какую-то простую операцию.

Это базовая модель искусственного нейрона.
Нейрон вычисляемый только с помощью скалярного произведения - вектор на вектор
Вместо этого можно использовать полиномиальное...
Пады нейронов
Преобразование осуществяется нелинейным способом

Для передачи нейронов xы должны быть большими или система должна пониамать и тогда
весы уже большие (опыт)
w0 - начальное (пороговое) значение

Какие функции активации есть?
1) Пороговая
Анализируется уровень активности нейрона и если он больше какой-либо величины,
то выдаем 0 или 1 - простейшая нелинейная функция и разрывная! Не ялвяется
дифференцируемой.
2) Линейная пороговая функция
Является непрерывной - в начале 0, потом 1, а на [T1, T2] возрастает.
3) Гиперболический тангенс (биполярная сигмоидная функция активации) [-1; 1]
4) Сигмоидная логистическая [0; 1] (похожа на закорючку)


Перцептрон - нейросеть с порогом функции активации.
Перцептрон - там где пороговая функция активации
Сейчас подразумевают что это нейросеть прямого распространения.

Как вычисляется выход?
Уровень активности нейрона и сравнивается с пороговым значением. На выходе будет 1.
Такой перцептрон может генерировать булевые функции
Эта логическая функция может выступать для распознавания вида животного, например (образ)
Что сделать чтобы решить данную задачу
Есть 2 входа - x1 и x2. Каждому соответствует вес перцепрторна w1, w2, порог T
Чтобы перцептрон выдавал правильный ответ
